{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- 패키지 임포트\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "from collections import Counter # 형태소별 빈도 구할 때 사용\n",
    "from IPython.display import clear_output\n",
    "from IPython import display # 램효율을 늘리기 위해 아웃풋 display를 지워줄 것.\n",
    "from ipywidgets import Output\n",
    "\n",
    "out = Output()\n",
    "display.display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 파일 불러오기 '''\n",
    "df = pd.read_csv(\"../나무문화/2022/나무문화_본문_9월_전처리.csv\", encoding='UTF-8')\n",
    "print(df.shape, df.columns)\n",
    "corpus = df['split_str'].to_list() # 문장(X문서X)으로 가져와서 실행.\n",
    "# ↑ 추후에 다른 분석 시도할 때 문장 별 형태소가 필요할 때도 있음. 문장별 형태소와 이를 문서로 합친 게 있으면 편하기 때문에 문장별로 형태소 분석 실행.\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 형태소 분석 '''\n",
    "nouns = []\n",
    "verbs = []\n",
    "adjs = []\n",
    "josas = [] # 불용어 목록에 조사 사용하기 위함.\n",
    "morphs = [] # 품사 태깅 없이 형태소만 추출. 추후 TF-IDF, N-gram등 텍스트 분석은 이 데이터로 진행함.\n",
    "pos_list = [] # 감성분석할 때 필요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(corpus))):\n",
    "    # 답변에서 형태소/품사 추출\n",
    "    try:\n",
    "        a = okt.pos(corpus[i], norm=True, stem=True) # 단어의 정규화와 어간 추출을 실행(True).\n",
    "        m = okt.morphs(corpus[i], norm=True, stem=False)\n",
    "        morphs.append(m) # 형태소 추가\n",
    "        pos_list.append(a) # 형태소/품사 추가\n",
    "        #print(i)\n",
    "        for x, y in a:\n",
    "            # 품사가 명사면 명사 리스트에 단어 추가\n",
    "            if y == 'Noun':\n",
    "                nouns.append(x)\n",
    "            # 품사가 동사면 동사 리스트에 단어 추가\n",
    "            elif y == 'Verb':\n",
    "                verbs.append(x)\n",
    "            # 품사가 형용사면 형용사 리스트에 단어 추가\n",
    "            elif y == 'Adjective':\n",
    "                adjs.append(x)\n",
    "\t\t    # 품사가 조사면 조사 리스트에 단어 추가.\n",
    "            elif y == 'Josa':\n",
    "                josas.append(x)\n",
    "    except:\n",
    "        pass\n",
    "    #display.clear_output(wait=True) # 출력지우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명사, 동사, 형용사 리스트에서 10개 단어씩 출력해서 확인\n",
    "print(nouns[0:10])\n",
    "print(verbs[0:10])\n",
    "print(adjs[0:10])\n",
    "print(josas[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 명사, 동사, 형용사, 조사 똑같이 아래 코드 반복 '''\n",
    "# 명사 리스트에서 명사 빈도 리스트 생성\n",
    "print(len(Counter(nouns))) # 이 값을 밑에 most_common 안에 넣으면 됨.\n",
    "noun_cnt = Counter(nouns).most_common()\n",
    "\n",
    "명사 = []\n",
    "명사빈도 = []\n",
    "for a, b in noun_cnt:\n",
    "    명사.append(a)\n",
    "    명사빈도.append(b)\n",
    "\n",
    "# 단어와 빈도를 가지고 판다스 데이터프레임(엑셀 표와 비슷) 생성\n",
    "noun_df = pd.DataFrame({'명사':명사, '빈도':명사빈도})\n",
    "# 명사 데이터프레임을 파일로 저장. .xlsx, .csv, .txt 등 가능.\n",
    "noun_df.to_csv(\"파일 저장 경로\", index=False, encoding='UTF-8')\n",
    "noun_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('NIFS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef870b4feb386425c661b7ebcadef1c9affb03996f900964fa02bf03ee560957"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
