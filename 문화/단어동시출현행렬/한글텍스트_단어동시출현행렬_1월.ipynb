{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 패키지 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 본문to형태소(morphs) 파일\n",
    "df = pd.read_csv(\"../dataset/2022/본문_형태소분석/1월/나무문화_1월_형태소분석.csv\", encoding='UTF-8')\n",
    "print(df.shape, df.columns)\n",
    "docs = df['칼럼명'].to_list()\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 각각의 본문이 str타입('나는 어제 밥을 먹었다')일 경우 list(['나', '는', '어제', '밥', '을' '먹다', '이다'])로 바꿔줌\n",
    "docs2 = docs.copy()\n",
    "for i in tqdm(range(len(docs))):\n",
    "    docs2[i] = docs2[i].split()\n",
    "\n",
    "\n",
    "#### 명사 빈도 상위 50개 단어 파일\n",
    "topwords_df = pd.read_csv(\"파일경로\", encoding='UTF-8')\n",
    "print(topwords_df.shape, topwords_Df.columns)\n",
    "topwords50 = topwords_df['칼럼명'].to_list()\n",
    "print(len(topwords50))\n",
    "print(topwords50)\n",
    "\n",
    "\n",
    "%%time #소요시간 보려고 만든 거니까 없어도 됨.\n",
    "#### 중복 단어 제거하여 리스트 생성\n",
    "unique_lines = [list(set(line)) for line in tqdm(docs2)]\n",
    "\n",
    "\n",
    "#### 중복 제거 잘 됐나 개수로 확인\n",
    "print(len(docs[0]))\n",
    "print(len(unique_lines[0]))\n",
    "print(unique_lines[0][0:10])\n",
    "\n",
    "\n",
    "#### 전체 단어쌍 빈도 dict 형식으로 생성\n",
    "freq_count = {}   #동시출현 빈도가 저장될 dict\n",
    "for words in tqdm(unique_lines):\n",
    "    # 전체 단어에 대한 동시 출현 빈도\n",
    "    for i, a in enumerate(words):\n",
    "        for b in words[i+1:]:\n",
    "            if a == b: continue\n",
    "            elif a>b:\n",
    "                freq_count[b, a] = freq_count.get((b, a),0) + 1\n",
    "            else :\n",
    "                freq_count[a, b] = freq_count.get((a, b),0) + 1\n",
    "\n",
    "\n",
    "\n",
    "#### 딕셔너리를 데이터프레임에 담기\n",
    "tt_freq_df=pd.DataFrame.from_dict(tt_freq_count, orient='index')\n",
    "\n",
    "\n",
    "#### 딕트to데이터프레임 저장\n",
    "freq_df.to_csv(\"파일저장경로/파일명.txt\", encoding='UTF-8')\n",
    "\n",
    "\n",
    "\n",
    "%%time #소요시간 보려고 만든 거니까 없어도 됨.\n",
    "#### dict형식을 컬럼명 지정해서 데이터프레임으로 만들기\n",
    "list1 = [(freq_df.index[i][0], freq_df.index[i][1], freq_df[0][i]) for i in tqdm(range(len(freq_df)))]\n",
    "freq_df2 = pd.DataFrame(list1, columns=[\"term1\",\"term2\",\"freq\"])\n",
    "print(freq_df2.shape)\n",
    "freq_df2.head()\n",
    "\n",
    "\n",
    "\n",
    "#### 컬럼명 지정한 dict_to_데이터프레임 저장\n",
    "freq_df2.to_csv(\"파일저장경로/파일명.txt\", index=False, encoding='UTF-8')\n",
    "\n",
    "\n",
    "\n",
    "%%time #소요시간 보려고 만든 거니까 없어도 됨.\n",
    "#### 50위 이내에 속한 단어들로 이루어진 Dataframe을 추출\n",
    "list2 =[(freq_df2.loc[i][0], freq_df2.loc[i][1], freq_df2.loc[i][2]) for i in tqdm(range(len(freq_df2))) if (freq_df2['term1'][i] in topwords50) &(freq_df2['term2'][i] in topwords50)]\n",
    "freq_df3 = pd.DataFrame(list2, columns=[\"term1\",\"term2\",\"freq\"])\n",
    "freq_df3\n",
    "\n",
    "\n",
    "\n",
    "#### 상위50위 단어들로 이루어진 단어쌍 데이터프레임 저장\n",
    "freq_df3.to_csv(\"파일저장경로/파일명.txt\", index=False, encoding='UTF-8')\n",
    "\n",
    "\n",
    "\n",
    "#### 공출현빈도(1-mode matrix) 만들기\n",
    "word_co_matx = np.zeros((50,50))\n",
    "mat_idx = topwords50 # 단어동시출현행렬이니까 인덱스와 칼럼을 동일하게 지정\n",
    "mat_col = topwords50\n",
    "word_co_matx = pd.DataFrame(word_co_matx, index=mat_idx, columns=mat_col)\n",
    "print(word_co_matx.shape)\n",
    "\n",
    "\n",
    "#### 단어쌍의 첫 번째 단어가 인덱스와 같다 and 두 번째 단어가 칼럼과 같다 → 단어쌍빈도를 해당 셀 값에 삽입\n",
    "for n in tqdm(range(len(freq_df3))):\n",
    "    for idx in mat_idx:\n",
    "        if idx == freq_df3['term1'][n]:\n",
    "            for col in mat_col:\n",
    "                if col == freq_df3['term2'][n]:\n",
    "                    word_co_matx.loc[idx, col] = freq_df3['freq'][n]\n",
    "                    word_co_matx.loc[col, idx] = freq_df3['freq'][n]\n",
    "\n",
    "\n",
    "\n",
    "#### 1-mode 매트릭스 확인하기\n",
    "tt_word_co_matx\n",
    "\n",
    "\n",
    "#### 공출현빈도 데이터프레임 저장하기~~\n",
    "#### ※ 인덱스가 저장돼야 하므로 index 파라미터 지정하지 말 것.\n",
    "word_co_matx.to_csv(\"파일저장경로/파일명.txt\", encoding='UTF-8')\n",
    "word_co_matx.to_excel(\"파일저장경로/파일명.xlsx\", encoding='UTF-8')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('NIFS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef870b4feb386425c661b7ebcadef1c9affb03996f900964fa02bf03ee560957"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
